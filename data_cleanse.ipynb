{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import & cleanse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('dataset/wikihan-romanization.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = raw_df[['Character', 'Middle Chinese (Baxter and Sagart 2014)', 'Cantonese', \n",
    "          'Mandarin']]\n",
    "df2 = df2.rename(columns={'Middle Chinese (Baxter and Sagart 2014)': 'Middle Chinese'})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows that are not fully recorded\n",
    "def drop_missing_raws(df):\n",
    "    df = df.replace('-', pd.NA)\n",
    "    row_missing_values = df.isnull().sum(axis=1)\n",
    "    fully_filled_rows = row_missing_values[row_missing_values == 0]\n",
    "    df = df.iloc[fully_filled_rows.index]\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "df2 = drop_missing_raws(df2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the table representation\n",
    "df2['Middle Chinese'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_characters(df):\n",
    "    unique_characters = {}\n",
    "\n",
    "    for column in df.columns:\n",
    "        combined_values = ''.join(df[column].astype(str))\n",
    "        unique_chars = set(combined_values)\n",
    "        unique_characters[column] = unique_chars\n",
    "\n",
    "    return unique_characters\n",
    "\n",
    "def print_all_chars(df):\n",
    "    for column, unique_chars in get_unique_characters(df).items():\n",
    "        print(f'{column}: {\", \".join(unique_chars)}')\n",
    "\n",
    "print(print_all_chars(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chapital letter to small letter\n",
    "df2['Mandarin'] = df2['Mandarin'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Delete after slash '/'\n",
    "def delete_after_slash(df):\n",
    "    def delete_after_slash_util(row):\n",
    "        return row.split('/')[0]\n",
    "    return df.applymap(delete_after_slash_util)\n",
    "\n",
    "df2 = delete_after_slash(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = list(df2['Character'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Normalize the tone representation\n",
    "# a. Cantonese\n",
    "tone_map = dict()\n",
    "tone_map['Middle Chinese'] = {u\"\\u00b9\": '1', u\"\\u00b2\": '2', u\"\\u00b3\": '3', u\"\\u2074\": '4'}\n",
    "def tone_converter(df, column, tone_map):\n",
    "    tone_map_col = tone_map[column]\n",
    "    for i in range(len(df[column])):\n",
    "        row = df[column][i]\n",
    "        for key in list(tone_map_col.keys()):\n",
    "            if key in row:\n",
    "                print(df[column][i], end=' -> ')\n",
    "                row_list = list(df[column][i])\n",
    "                row_list[row.index(key)] = tone_map_col[key]\n",
    "                temp = \"\".join(row_list)\n",
    "                temp = ''.join([i for i in temp if not i.isdigit()]) + ''.join([i for i in temp if i.isdigit()])\n",
    "                df[column][i] = temp\n",
    "                print(df[column][i])\n",
    "    return df\n",
    "\n",
    "df2 = tone_converter(df2, 'Middle Chinese', tone_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Mandarin\n",
    "tone_map['Mandarin'] = {\n",
    "    '\\u0101': 'a1',\n",
    "    '\\u00e1': 'a2',\n",
    "    '\\u01ce': 'a3',\n",
    "    '\\u00e0': 'a4',\n",
    "    '\\u014d': 'o1',\n",
    "    '\\u00f3': 'o2',\n",
    "    '\\u01d2': 'o3',\n",
    "    '\\u00f2': 'o4',\n",
    "    '\\u0113': 'e1',\n",
    "    '\\u00e9': 'e2',\n",
    "    '\\u011b': 'e3',\n",
    "    '\\u00e8': 'e4',\n",
    "    '\\u012b': 'i1',\n",
    "    '\\u00ed': 'i2',\n",
    "    '\\u01d0': 'i3',\n",
    "    '\\u00ec': 'i4',\n",
    "    '\\u016b': 'u1',\n",
    "    '\\u00fa': 'u2',\n",
    "    '\\u01d4': 'u3',\n",
    "    '\\u00f9': 'u4',\n",
    "    '\\u01d6': 'ü1',\n",
    "    '\\u01d8': 'ü2',\n",
    "    '\\u01da': 'ü3',\n",
    "    '\\u01dc': 'ü4'\n",
    "}\n",
    "print(tone_map['Mandarin'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = tone_converter(df2, 'Mandarin', tone_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_chars(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_rows_with_character(df, column, character):\n",
    "    matching_rows = df[df[column].str.contains(character, na=False)]\n",
    "    \n",
    "    if not matching_rows.empty:\n",
    "        print(f\"Rows in column '{column}' containing '{character}':\")\n",
    "        print(matching_rows)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locate_rows_with_character(df2, 'Mandarin', '㣇')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Mandarin'][11233] = 'yi4'\n",
    "df2.iloc[11233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_chars(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('./dataset/ltc_yue_cmn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we have only Cantonese input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yue = raw_df[['Character', 'Cantonese', \n",
    "          'Mandarin']]\n",
    "df_yue = drop_missing_raws(df_yue)\n",
    "df_yue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanse Mandarin\n",
    "df_yue['Mandarin'] = df_yue['Mandarin'].str.lower()\n",
    "df_yue = delete_after_slash(df_yue)\n",
    "\n",
    "df_yue = tone_converter(df_yue, 'Mandarin', tone_map)\n",
    "df_yue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all_chars(df_yue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_list = ['ḿ', 'ề', 'ǹ','\\u0300', '䴉', '㣇', 'ń']\n",
    "for outl in outlier_list:\n",
    "    locate_rows_with_character(df_yue, 'Mandarin', outl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yue = df_yue.drop([1545, 2005, 6139, 11457, 1929, 1546, 1719, 1928])\n",
    "df_yue['Mandarin'][15136] = 'yi4'\n",
    "df_yue['Mandarin'][16046] = 'huan2'\n",
    "print_all_chars(df_yue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanse Cantonese\n",
    "locate_rows_with_character(df_yue, 'Cantonese', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yue = df_yue.drop([967, 969, 971, 972, 974, 976, 1923, 8065])\n",
    "df_yue = df_yue.reset_index(drop=True)\n",
    "print_all_chars(df_yue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yue.to_csv('./dataset/yue_cmn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
